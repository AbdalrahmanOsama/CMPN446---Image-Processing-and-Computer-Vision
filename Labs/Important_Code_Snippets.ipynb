{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mahinour's Lab Exam Summary  ~~"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "from commonfunctions import *\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TOC:\n",
    "1. Coding Notes\n",
    "2. Some Theory from lecs related to labs\n",
    "3. Some code snippets from labs + lab exams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Coding Notes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### * arrays and slicing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Lists: ----------------------------\")\n",
    "\n",
    "my_list = [10, 20, 30, 40, 50]\n",
    "print(my_list[0])   # Output: 10\n",
    "print(my_list[2])   # Output: 30\n",
    "print(my_list[-1])  # Output: 50\n",
    "\n",
    "\n",
    "#The syntax for slicing is start:stop:step, where start is the starting index, stop is the ending index (exclusive), and step is the step size between elements.\n",
    "print(my_list[1:4])   # Output: [20, 30, 40]\n",
    "print(my_list[:3])    # Output: [10, 20, 30]\n",
    "print(my_list[::2])   # Output: [10, 30, 50]\n",
    "\n",
    "\n",
    "print(\"2D Matrix: ----------------------------\")\n",
    "\n",
    "#For 2D matrix:\n",
    "'''\n",
    "Axis 0 (rows) --> | 1  2  3 |\n",
    "Axis 1 (columns) | 4  5  6 |\n",
    "                 | 7  8  9 |\n",
    "'''\n",
    "\n",
    "Arr2d = np.array([[1, 2, 3],\n",
    "                 [4, 5, 6],\n",
    "                 [7, 8, 9]])\n",
    "\n",
    "# Slicing to access a submatrix\n",
    "submatrix = Arr2d[0:2, 1:3]\n",
    "print(submatrix)\n",
    "# Output:\n",
    "# [[2 3]\n",
    "#  [5 6]]\n",
    "\n",
    "\n",
    "\n",
    "#For 3D matrix:\n",
    "'''\n",
    "Axis 0 (depth)   Axis 1 (rows)   Axis 2 (columns)\n",
    "|  [ [ [1, 2, 3], [4, 5, 6], [7, 8, 9] ],\n",
    "   [ [10, 11, 12], [13, 14, 15], [16, 17, 18] ],\n",
    "   [ [19, 20, 21], [22, 23, 24], [25, 26, 27] ] ]\n",
    "'''\n",
    "\n",
    "\n",
    "print(\"3D Matrix: ----------------------------\")\n",
    "\n",
    "# Create a 3D NumPy array with shape (5, 5, 5) and data type uint8\n",
    "Arr3d = np.zeros(shape=(5, 5, 5), dtype=np.uint8)\n",
    "\n",
    "print(\"Arr1\")\n",
    "print(Arr3d)\n",
    "\n",
    "\n",
    "# Modify a portion of the array to set elements to 20\n",
    "Arr3d[0:3, 0:2, 1] = 20\n",
    "print(Arr3d)\n",
    "\n",
    "# Columns (Axis 0): Slicing from column index 0 to 2 (inclusive).\n",
    "# Rows (Axis 1): Slicing from row index 0 to 1 (inclusive).\n",
    "# Depth (Axis 2): Selecting the element at depth index 1.\n",
    "\n",
    "# # order:  cell  row   column\n",
    "\n",
    "\n",
    "\n",
    "# complement:\n",
    "\n",
    "array1 = np.array([1, 2, 3, 4, 5])\n",
    "array2 = np.array([3, 4, 5, 6, 7])\n",
    "\n",
    "complement_array = np.setdiff1d(array1, array2)\n",
    "print(complement_array)\n",
    "\n",
    "# union:\n",
    "\n",
    "array1 = np.array([1, 2, 3, 4, 5])\n",
    "array2 = np.array([3, 4, 5, 6, 7])\n",
    "\n",
    "union_array = np.union1d(array1, array2)\n",
    "print(union_array)\n",
    "\n",
    "# intersect:\n",
    "\n",
    "\n",
    "array1 = np.array([1, 2, 3, 4, 5])\n",
    "array2 = np.array([3, 4, 5, 6, 7])\n",
    "\n",
    "intersection_array = np.intersect1d(array1, array2)\n",
    "print(intersection_array)\n",
    "\n",
    "\n",
    "# complement:\n",
    "img=None\n",
    "imgC= np.logical_not(img)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ** some fns and attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "########################### Common Functions #########################\n",
    "print(Arr3d.shape)   #==> Attribute for Numpy array   ==>    Gets the shape of the matrix (Array).\n",
    "\n",
    "io.imread            #==>        Function             ==>             Reads an image into a Numpy matrix\n",
    "io.imshow            #==>        Function             ==>             Shows an image to a plot\n",
    "plt.figure           #==>        Function             ==>             Generates a new figure\n",
    "rgb2gray             #==>        Function             ==>             Converts RGB image to Gray\n",
    "rgb2hsv              #==>        Function             ==>             Converts RGB image to HSV\n",
    "histogram            #==>        Function             ==>             Gets histogram of an image\n",
    "\n",
    "\n",
    "########################### Showing Images ##########################\n",
    "show_images          #==>        Function             ==>             Takes two arrays one for images’ matrices and the second for images’ titles and draws images accordingly \n",
    "#show_images([img1,img2],[‘Title1’,’Title2’]\n",
    "\n",
    "#Another way to show images using subplots: \n",
    "# creating figure with 2 plots 1 row 2 columns with 6,2 dimension\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(6, 2))\n",
    "fig.suptitle('No.1')\n",
    "\n",
    "# ax1.imshow(img)\n",
    "# ax1.set_title('Original RGB')\n",
    "\n",
    "# note we have to write down cmap=\"gray\" if grayscale\n",
    "#Side Note: cmap stands for \"colormap\" in Matplotlib, which is a library used for creating visualizations and plots in Python. A colormap is a mapping of values in your data to colors, allowing you to represent your data in a visually informative way.\n",
    "#if we removed cmap then it will still be grayscale but represented incorrectly, while if we kept it and removed the rgb2gray method above it will give the rgb normally as it doesnt convert, it only maps\n",
    "\n",
    "# ax2.imshow(gray_img, cmap=\"gray\")\n",
    "# ax2.set_title('Gray Scale')\n",
    "\n",
    "                                                                                  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bintodec(binary):\n",
    "    return sum(val*(2**idx) for idx, val in enumerate(reversed(binary)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 2- Retreive the 3 channels of the image(R,G,B) \n",
    "red_channel= img[:,:,0]\n",
    "green_channel= img[:,:,1]\n",
    "blue_channel=img[:,:,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VIP**\n",
    "gry= rgb2gray(img)   # not all images need this, if they are already gray dont use this\n",
    "# sometimes we might need to use rgba2rgb first then rgb2gray\n",
    "gry *=255  # note that some images might cause overflow, so don't use this on all images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ** some image tricks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Image:\n",
      "[[100 150 200]\n",
      " [ 50  75 100]\n",
      " [ 25  50  75]]\n",
      "\n",
      "Padded Image:\n",
      "[[  0   0   0   0   0]\n",
      " [  0 100 150 200   0]\n",
      " [  0  50  75 100   0]\n",
      " [  0  25  50  75   0]\n",
      " [  0   0   0   0   0]]\n"
     ]
    }
   ],
   "source": [
    "grayscale_img = np.array([[100, 150, 200],\n",
    "                          [50, 75, 100],\n",
    "                          [25, 50, 75]], dtype=np.uint8)\n",
    "\n",
    "\n",
    "\n",
    "# how we loop on image:\n",
    "######################\n",
    "\n",
    "for x in range(grayscale_img.shape[0]):\n",
    "        for y in range(grayscale_img.shape[1]):\n",
    "            pixel=grayscale_img[x,y]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# if we want to add padding to the image:\n",
    "########################################\n",
    "\n",
    "# Specify the amount of padding for each side (top, bottom, left, right)\n",
    "top_pad, bottom_pad, left_pad, right_pad = 1, 1, 1, 1\n",
    "\n",
    "# Add padding with zeros\n",
    "padded_img = np.pad(grayscale_img, ((top_pad, bottom_pad), (left_pad, right_pad)), mode='constant', constant_values=0)\n",
    "\n",
    "# Display the original and padded images\n",
    "print(\"Original Image:\")\n",
    "print(grayscale_img)\n",
    "\n",
    "print(\"\\nPadded Image:\")\n",
    "print(padded_img)\n",
    "\n",
    "\n",
    "\n",
    "# Turning image to binary\n",
    "binary_image = grayscale_img > 0.5    #only if range (0-1)\n",
    "\n",
    "\n",
    "# to get height and width:\n",
    "height, width = np.shape(grayscale_img)\n",
    "\n",
    "\n",
    "# type:\n",
    "binary_image = binary_image.astype(int)\n",
    "grayimg=np.uint8(img*255)\n",
    "image = img.astype(float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Random Theory Notes:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <u>Lecture 1</u>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Image matrices are**\n",
    "<br>\n",
    "o 2D matrix: {0, 1} in Binary Images.\n",
    "<br>\n",
    "o 2D matrix: double[0, 1] or uint8[0, 255] in Intensity Images (Gray Scale).\n",
    "<br>\n",
    "o 3D matrix (MxNx3)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‘salt’\n",
    "Replaces random pixels with 1.\n",
    "\n",
    "‘pepper’\n",
    "Replaces random pixels with 0 (for unsigned images) or -1 (for signed images)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To separately get the Hue, Saturation and Value channels, use hsvImg[:,:,X]\n",
    "<br>\n",
    "Hue is the first channel, Saturation is the second and value is the last channel.\n",
    "<br>\n",
    "\n",
    "Hue is for color \"cycle\"\n",
    "More saturation (right) means strong color\n",
    "Less Saturation (left) means weak color  \n",
    "Value is for value where (down) means less brightness \"black\" and (up) more brightness \"white\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Histograms:\n",
    "<br>\n",
    "Histogram captures the distribution of gray levels in the image. “How frequently each \n",
    "gray level occurs in the image”  (number of pixels for each gradient)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Co-occurrence matrix : It describes how often a pixel with intensity I occur in a \n",
    "specific spatial relationship to a pixel with intensity J\n",
    "<br>\n",
    "“how many times did 0 get beside 0 or we have (0-7)”. This helps in determining the texture later on.\n",
    "<br>\n",
    "<br>\n",
    "GLCM: Gray Scale Co-occurrence Matrix - the spatial relationship is defined as the pixel of interest and the pixel to its immediate right (horizontally adjacent)\n",
    "\n",
    "<br>\n",
    "Its dimensions are (nxn) where n is highest intensity of gray level i.e. 8 or 256"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chain codes:\n",
    "The border is defined by the coordinates of its reference pixel and the \n",
    "sequence of symbols. “we have a start point and a chain code string till we reach back to \n",
    "start point again”\n",
    "<br>\n",
    "starting from 0 from left and anticlock wise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <u>Lecture 2</u>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. space Domain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can check convolution in summary p.14 & p,17 for the matrices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- low pass filter: smoothing and high blury\n",
    "- High pass filter: Edge detection and sharpening"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Frequency Domain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fourier Transform convert the image from Spatial Domain to Frequency Domain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Steps: convert to frequency domain, filter in frequency domain, multiply, convert \n",
    "to space domain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dimensions doesnt matter in frequency domain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the frequency of the image we can know If the changes are high or low, if \n",
    "change is slow (lines far away) then lower frequency \"small distance between 2 pts in FD\", while if changes are fast\n",
    "(lines close together) then higher frequency \"longer distance between 2 pts in FD\".\n",
    "<br>\n",
    "\n",
    "check the code snippet below**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convolution in FD:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Huge changes gets removed (low pass filter where we pass the one with low \n",
    "frequency (white one), while the rest (black) don’t pass)\n",
    "- If we increased frequency (white box) ==> Blur will decrease, and more edges will \n",
    "appear\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Eliminating high frequencies blurs the image.  \"black outside and white inside\"\n",
    "- Eliminating low frequencies gives you edges.   \"white outside and black inside\"\n",
    "- And enhancing high frequencies while keeping the low frequencies sharpens the \n",
    "image.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <u>Lecture 3</u>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the image enhancment snippets below with their explanation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <u>Lecture 4</u>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Smoothing: suppresses high frequencies “decrease noise/edges”\n",
    "- Gradient operators: suppresses low frequencies. “increase edges/noise”\n",
    "\n",
    "<br>\n",
    "\n",
    "- Additive Noise (Ex. Gaussian): Random noise n(i,j) added to random pixel value I(i,j) where Inew(i,j)= I(i,j)+ n(i,j) \"any grayscale value\"\n",
    "- Impulsive (Salt and Pepper): The random pixels become either 0 or 1 only. “black or white” \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LPT-Smoothing: Using Averaging “without filters”:  Equation in p.30 in summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LPT-Smoothing: Using Linear Filters (Averaging, Gaussian) \n",
    "<br>\n",
    "\n",
    "- Mean Filter: LPF    when we increase size of filter, noise is less but blurring becomes serious disadvantage\n",
    "- Gaussian Filter: LPF  we can increase size of filter with sigma=1 and will give better results than mean filter, but increasing sigma causes more blurrniess too.\n",
    "<br>\n",
    "\n",
    "Unlike Mean averaging, Gaussian filter is a more sophisticated filter that uses a Gaussian \n",
    "function to weight the neighboring pixels. The Gaussian function gives more weight to \n",
    "pixels that are closer to the center pixel and less weight to pixels that are further away. \n",
    "This allows the filter to capture more of the local information in the image while \n",
    "reducing the noise.\n",
    "<br>\n",
    "\n",
    "When sigma=1 then we are focusing on the middle pixel, and when we increase sigma, \n",
    "this means we will focus on giving more weights to the middle pixel and its \n",
    "neighborhood \n",
    "<br>\n",
    "\n",
    "could be : 1/10 [1,1,1 ; 1,2,1 ; 1,1,1]   OR  1/16 [1,2,1 ; 2,4,2 ; 1,2,1]   (NB:  we divide by number of pixels)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LPT-Smoothing: Using Non- Linear Filters (Min, Max , Median)\n",
    "<br>\n",
    "\n",
    "- Max filter: The max value replaces the current pixel ➔ brighter image.\n",
    "- Min filter: The min value replaces the current pixel ➔ darker image.\n",
    "<br>\n",
    "\n",
    "but not always the best to use, can take max and noise remains instead of taking min and removing noise.\n",
    "\n",
    "- Median Filter: Good for impulsive noise (salt and pepper) and sharp edges are kept\n",
    "<br>\n",
    "\n",
    "In the previous example, getting the median will be: [0,0,0,0,0,0,0,0,255]=0 so noise removed.\n",
    "<br>\n",
    "\n",
    "How it works: The median filter works by moving through the image pixel by pixel, replacing each value with the median value of neighboring pixels\n",
    "<br>\n",
    "\n",
    "Dis: fine features and sharp thin corners or edges are damaged, however by choosing other shapes than rectangle edges can be preserved. Its also time consuming and high complexity\n",
    "<br>\n",
    "\n",
    "Adv: No new values are added (values from image) + good with impulsive noise\n",
    "\n",
    "<br>\n",
    "\n",
    "Check concept of rotating mask in lec p.36"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <u>Lecture 5</u>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "check code snippets below"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <u>Lecture 6</u>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Erosion: fit \"thinning and removing unwanted objects\"   [min]\n",
    "- Dilation: Hit \"connect disconnected components, and region growing   [max]\n",
    "- Opening: Erosion followed by dilation\n",
    "- Closing: dilation followed by erosion\n",
    "\n",
    "<br>\n",
    "\n",
    "Region Filling Algo:   p.61\n",
    "<br>\n",
    "\n",
    "p is the point inside the boundary, with the value of 1 \n",
    "X(k) = (X(k-1) dilate B) conjunction with complemented A \n",
    "The process stops when X(k) = X(k-1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Some Code Snippets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################### Random Noise \"Salt and pepper\" ###############################\n",
    "random_noise         #==>        Function             ==>             Adds noise to image\n",
    "#EX: noise005=random_noise(gray_img, mode=\"s&p\") #default is amount=0.05\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.         0.         0.         ... 0.         0.         0.        ]\n",
      " [0.00390625 0.00390625 0.00390625 ... 0.00390625 0.00390625 0.00390625]\n",
      " [0.0078125  0.0078125  0.0078125  ... 0.0078125  0.0078125  0.0078125 ]\n",
      " ...\n",
      " [0.98828125 0.98828125 0.98828125 ... 0.98828125 0.98828125 0.98828125]\n",
      " [0.9921875  0.9921875  0.9921875  ... 0.9921875  0.9921875  0.9921875 ]\n",
      " [0.99609375 0.99609375 0.99609375 ... 0.99609375 0.99609375 0.99609375]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#########################################   Historgram  ###############################\n",
    "# 1.                We can use this:\n",
    "def showHistFunction(img,histogramImg):\n",
    "    plt.figure()\n",
    "    bar(histogramImg[1]*255, histogramImg[0], width=0.8, align='center')\n",
    "'''\n",
    "1- Show Historgram with different bins\n",
    "'''\n",
    "#where nbins represent number of bins (256 bins, 8 bins or 64 bins only)\n",
    "# histogram_ex1_1 = histogram(rgb2gray(ex1), 256)\n",
    "# histogram_ex1_2 = histogram(rgb2gray(ex1), 64)\n",
    "# histogram_ex1_3 = histogram(rgb2gray(ex1), 8)\n",
    "# showHistFunction(ex1, histogram_ex1_1)\n",
    "# showHistFunction(ex1, histogram_ex1_2)\n",
    "# showHistFunction(ex1, histogram_ex1_3)\n",
    "\n",
    "'''\n",
    "2- Draw a grey-scale image that has uniform histogram \n",
    "same number of pixels for all intensity levels) using code only. Let the size of the image be 256x256.\n",
    "use np.ones to draw image with ones.\n",
    "'''\n",
    "grayscale_img = np.ones((256, 256))\n",
    "\n",
    "for i in range(256):\n",
    "    grayscale_img[i,:] = i/256.0\n",
    "print(grayscale_img)\n",
    "test = histogram(grayscale_img, nbins=8)\n",
    "showHistFunction(grayscale_img, test)\n",
    "show_images([grayscale_img])\n",
    "\n",
    "\n",
    "## 2. We can just use ShowHist given from the common functions file, but note that they are different.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Space Domain Filters & Conv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "Low_pass_filter_sd =np.ones((3,3)) * 1/9\n",
    "\n",
    "high_pass_filter_sd =np.ones((3,3)) \n",
    "high_pass_filter_sd[1,1]=-8\n",
    "\n",
    "horizontal_edge_detection_filter_sd =np.array([\n",
    "    [ 1,1, 1],\n",
    "    [0, 0,0],\n",
    "    [ -1,-1, -1]\n",
    "])\n",
    "                     \n",
    "vertical_edge_detection_filter_sd = np.transpose(horizontal_edge_detection_filter_sd)\n",
    "\n",
    "# filtered_img = convolve2d(img,filter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Frequency Domain & Frequency Filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#########################################   Frequency Domain  ###############################\n",
    "\n",
    "# This function maps matrices from frequency to space then plots them\n",
    "def plot_image_from_freq(freq_domain_mat):\n",
    "    inverse_fft_mat = fftpack.ifft2(freq_domain_mat) # Inverse FFT is a fast version of inverse DFT\n",
    "    # Due to approximations, the returned matrix contains complex numbers\n",
    "    # So, we get the magnitude to be able to plot the image\n",
    "    image = np.abs(inverse_fft_mat) \n",
    "    show_images([image], titles=['Image in Space Domain'])\n",
    "\n",
    "# Notice that in this case, we have very small distance between points so small change [large space between lines]\n",
    "# if we increased the distance (11) o sth else (21) the more changes and [smaller space between lines]\n",
    "# similary we can do it horizontally or vertically like lab 2\n",
    "freq_domain_mat = np.zeros([21,21])\n",
    "freq_domain_mat[9, 10] = 1 # The choice of the value '1' is arbitrary\n",
    "freq_domain_mat[11, 10] = 1\n",
    "plot_image_from_freq(freq_domain_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function applies a filter to an image in the frequency domain\n",
    "# and plots multiple images describing the process\n",
    "def apply_filter_in_freq(img, f):\n",
    "    img_in_freq = fftpack.fft2(img)\n",
    "    \n",
    "    # we supply the img shape here to make both the filter and img have the same shape to be able to multiply\n",
    "    filter_in_freq = fftpack.fft2(f, img.shape)\n",
    "    filtered_img_in_freq = np.multiply(img_in_freq, filter_in_freq)\n",
    "    filtered_img = fftpack.ifft2(filtered_img_in_freq)\n",
    "    \n",
    "    show_images([img,\n",
    "                fftpack.fftshift(np.log(np.abs(img_in_freq)+1)), # log for better intensity scale, \n",
    "                                                                 # shift to make zero freq at center\n",
    "                fftpack.fftshift(np.log(np.abs(filter_in_freq)+1)),\n",
    "                fftpack.fftshift(np.log(np.abs(filtered_img_in_freq)+1)),\n",
    "                np.abs(filtered_img)\n",
    "                ], ['Image', 'Image in Freq. Domain', 'Filter in Freq. Domain', 'Filtered Image in Freq. Domain', 'Filtered Image'])\n",
    "    \n",
    "\n",
    "# Let's try some filters in FD AFTER converting image to grayscale:\n",
    "    \n",
    "# This is a low pass filter (in frequency domain)  where black outside, white inside ==> cause smoothing and blurry\n",
    "# Note that this is considered gaussian (averaging giving more weights to neighbors inside)\n",
    "low_pass_filter_fd=np.array([\n",
    "    [1,2,1],\n",
    "    [2,4,2],\n",
    "    [1,2,1]\n",
    "])\n",
    "# This is a high pass filter (in frequency domain)  where black inside, white outside ==> cause edge detection\n",
    "high_pass_filter_fd=np.array([\n",
    "    [ 0,-1, 0],\n",
    "    [-1, 4,-1],\n",
    "    [ 0,-1, 0]\n",
    "])\n",
    "\n",
    "#then use apply_filter_in_freq\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image Enhancemnet "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################## Negative transformation ###################\n",
    "# 255-r\n",
    "def negative(img):\n",
    "    grayimg=rgb2gray(img*255)\n",
    "    grayimg=255-grayimg\n",
    "    return grayimg\n",
    "\n",
    "############################## Brightness Thresholding  ######################\n",
    "\n",
    "#It acts as a filter where for a certain range=>0 and the other range=>1 \n",
    "# Turns it into binary image\n",
    "\n",
    "\n",
    "############################### Contrast enhancemnt #######################\n",
    "#High contrast means more arrangement of colors in bigger range.\n",
    "#Low contrast means colors are gathered in one place (i.e. gathered to a certain pixel intensity) , i.e. a bright image has pixels towards white (low contrast)\n",
    "\n",
    "#It can use linear transformation  OR log: t(r)= c log(1+r)\n",
    "\n",
    "#Define function ‘Contrast_enhancement’ that Stretches the grey levels in the \n",
    "#range 0 to 100 into the range 50 – 200 and leaves other levels non changed. \n",
    "#What is the equation??? \n",
    "\n",
    "# hint: draw the spectrum of levels to know the equation, use for loops and if statements\n",
    "\n",
    "#Method 1:\n",
    "def Contrast_enhancement(img):\n",
    "    grayimg=(rgb2gray(img))    # might need to multiply by 255 or not according to image\n",
    "    print(grayimg.shape[0])\n",
    "    print(grayimg.shape[1])\n",
    "    for x in grayimg:\n",
    "        for y in x:\n",
    "            if(y>=0 and y<=100):\n",
    "                y=y*1.5+50\n",
    "    return grayimg\n",
    "\n",
    "#Method 2:\n",
    "def Contrast_enhancementmine(img):\n",
    "    grayimg=(rgb2gray(img))\n",
    "    i=0\n",
    "    for x in range(grayimg.shape[0]):\n",
    "        for y in range(grayimg.shape[1]):\n",
    "            pixel=grayimg[x,y]\n",
    "            if(pixel>=0 and pixel<=100):\n",
    "                pixel=pixel+(i*50)\n",
    "                i=i+1\n",
    "           \n",
    "    return grayimg\n",
    "\n",
    "\n",
    "\n",
    "############################## Gamma Correction #############################\n",
    "#fn: (𝐴′ = 𝑐 ∗ 𝐴^gamma)\n",
    "# c is always 1\n",
    "# gamma:\n",
    "#       If input is black: decreasing gamma decreases the black in the image\n",
    "#       If input is white: increasing gamma decreases the white in the image\n",
    "\n",
    "# check lab 4 to see effect\n",
    "def gammaCorrection(img,c,gamma):\n",
    "     grayimg=(rgb2gray(img)*255)\n",
    "     grayimg = (grayimg ** gamma) * c\n",
    "     return grayimg\n",
    "\n",
    "\n",
    "################################# HISTOGRAM EQUALIZATION ###########################################  # lab 4\n",
    "#p. 26 in the summary\n",
    "# helps in converting the image to high contrast\n",
    "\n",
    "#Images should be grayscaled, but first check if the given image was already grayscaled or not.\n",
    "# 1. get intensities and pixels arrays where:  intensities=imgHist[1]  &  pixels=imgHist[0]\n",
    "# 2. get pdf of all pixels where p(pxl_intensity)= number_of_pixels_at_this_intensity / number of pixels\n",
    "     # pdf=pixels/np.sum(pixels)\n",
    "# 3. T(pixel_intensity)= round(largestpixelintensity*  cdf)  \n",
    "        #where cdf= p(0)+p(1)+p(2).......\n",
    "# 4. When you get T : T are new pixel intensities so new pixel_val(T)= pixels\n",
    "\n",
    "\n",
    "'''\n",
    "4 Histogram Eq.\n",
    "Note: Histogram function of skimage returns only present intensity values not all 255\n",
    "You can use showHist function from commonfunctions file\n",
    "'''\n",
    "def getImageWithHist(img,nbins=256):\n",
    "    imgHist = histogram(img, nbins)\n",
    "    intensities=imgHist[1]\n",
    "    pixels=imgHist[0]\n",
    "\n",
    "    # print(np.sum(pixels))\n",
    "    pdf=pixels/np.sum(pixels)  #list of new pixels with their pdf\n",
    "\n",
    "    csum=0\n",
    "    t=[]  # New T values: new pixel intensity\n",
    "    for i in range(len(pdf)):    #pdf size is pixels size \n",
    "        csum=pdf[i]+csum\n",
    "        t.append(round(255*csum))\n",
    "\n",
    "    print(t[0:100])\n",
    "        \n",
    "    #now we need to get image:\n",
    "    copy=np.zeros(img.shape)\n",
    "\n",
    "    print(img)\n",
    "    for x in range(img.shape[0]):\n",
    "        for y in range(img.shape[1]):   \n",
    "            copy[x,y]=t[img[x,y]]\n",
    "    return copy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Smoothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#################################### Own Median Filter #############################\n",
    "'''\n",
    "edgex := (window width / 2) rounded down\n",
    "edgey := (window height / 2) rounded down\n",
    "for x from edgex to image width – edgex\n",
    "{\n",
    " for y from edgey to image height – edgey\n",
    " {\n",
    " allocate colorArray[window height][window width]\n",
    " for fx from 0 to window width\n",
    " for fy from 0 to window height\n",
    " colorArray[fy][fx] := inputPixelValue [y + fy - edgey] [x + fx - edgex]\n",
    " sort all entries in colorArray[][]\n",
    " outputPixelValue[y][x] := colorArray [window height / 2] [window width / 2]\n",
    " }\n",
    "}\n",
    "'''\n",
    "def medianFilter(img, window_width, window_height):\n",
    "    [h,w]= img.shape\n",
    "    edgex= math.floor(window_width/2)\n",
    "    edgey= math.floor(window_height/2)\n",
    "    outputImg=np.zeros(img.shape)\n",
    "\n",
    "    for y,x in itertools.product(range(edgey, h-edgey-1), range(edgex, w-edgex-1)):\n",
    "        colorArray=img[y-edgey:y+edgey+1, x-edgex:x+edgex+1]\n",
    "        outputImg[y,x]= np.median(colorArray,axis=None)\n",
    "\n",
    "    return outputImg\n",
    "\n",
    "\n",
    "# built_in_median=median(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################# Gaussian filter #########################\n",
    "\n",
    "# guassian1=skimage.filters.gaussian(img,sigma=8)    # very blurry\n",
    "# guassian2=skimage.filters.gaussian(img,sigma=3)     # smoothed\n",
    "# guassian3=skimage.filters.gaussian(img,sigma=0.2)   # less blur"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Edge Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################### derivative operators #####################\n",
    "#Derivative is all about the difference “change” between pixels.\n",
    "# local maxima or minim\n",
    "\n",
    "\n",
    "img= None\n",
    "\n",
    "# 1. Robert   #p.42\n",
    "robert_img= roberts(img)  #high sensitivity to noise, as very few pixels are used for approximation. (2x2)\n",
    "\n",
    "\n",
    "# 2. Perwitt\n",
    "perwitt_img= prewitt(img)  # in 8 directions\n",
    "\n",
    "# 3. Sobel\n",
    "\n",
    "# x and y only (3x3)\n",
    "#The difference between sobel and prewitt in x & y direction is that sobel gives more  weight to the direct neighbors\n",
    "\n",
    "sobel_img= sobel(img)\n",
    "sobel_img_h= sobel_h(img)\n",
    "sobel_img_v= sobel_v(img)\n",
    "\n",
    "\n",
    "# Custom Sobel (V-H-Both):\n",
    "def customSobel(image, threshold):\n",
    "    hx = [[-1, -2, -1], [0, 0, 0], [1, 2, 1]]\n",
    "    hy = [[-1, 0, 1], [-2, 0, 2], [-1, 0, 1]]\n",
    "\n",
    "    height, width = np.shape(image)\n",
    "\n",
    "    image_x_value = convolve2d(image, hx)\n",
    "    image_x_value[np.where(image_x_value < 0)] = 0\n",
    "\n",
    "    image_y_value = convolve2d(image, hy)\n",
    "    image_y_value[np.where(image_y_value < 0)] = 0\n",
    "\n",
    "    new_image = np.sqrt(np.square(image_x_value) + np.square(image_y_value))\n",
    "    new_image[np.where(new_image < threshold)] = 0\n",
    "    new_image[np.where(new_image >= threshold)] = 1\n",
    "\n",
    "    show_images([image_x_value, image_y_value, new_image])\n",
    "\n",
    "customSobel(img, 100)\n",
    "\n",
    "\n",
    "# 4. canny\n",
    "\n",
    "out4 = canny(img, sigma = 1.0, low_threshold = 50/255, high_threshold = 200/255)\n",
    "out5 = canny(img, sigma = 2.0, low_threshold = 50/255, high_threshold = 200/255)\n",
    "out6 = canny(img, sigma = 3.0, low_threshold = 50/255, high_threshold = 200/255)\n",
    "\n",
    "canny_img_def= canny(img, sigma=1)  #we can set ===> sigma, low_threshold, high_threshold\n",
    "canny_img_fine_details=canny(img, sigma=0.5)\n",
    "canny_img_good_edges=canny(img, sigma=1.5)\n",
    "canny_img_strong_edges=canny(img, sigma=4)\n",
    "\n",
    "canny_with_threshold_1=canny(img, high_threshold=80, low_threshold=50)\n",
    "canny_with_threshold_2=canny(img, high_threshold=100)  #when it keeps increasing (100 and more) only strong edges remain\n",
    "canny_with_threshold_3=canny(img, low_threshold=50)   # 50 is max (less noise) and 20 has more noise\n",
    "\n",
    "\n",
    "#The effect of the Canny operator is determined by three parameters: \n",
    "# ✓ the width of the Gaussian kernel used in the smoothing phase (σ) \n",
    "#    If kernel is so big, many edges would be smoothed and blurred so only Strong edges would remain, but less strong edges would vanish.\n",
    "#✓ the upper threshold of hysteresis \n",
    "#✓ and the lower threshold used by the tracker.\n",
    "\n",
    "#   Large σ detects large scale edges.\n",
    "#   Small σ detects fine features.\n",
    "#The upper tracking threshold can be set quite high, and the lower threshold quite low for good results. \n",
    "#Setting the lower threshold too high will cause noisy edges to break up. \n",
    "#Setting the upper threshold too low increases the number of spurious and undesirable edge fragments appearing in the output\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################ 2nd derivative operators #############################\n",
    "\n",
    "#check p.44\n",
    "\n",
    "# Laplace and Log operators\n",
    "\n",
    "#LOG:\n",
    "# ✓ Smooth Image with Gaussian Filter to remove noise first\n",
    "# ✓ Applying the Laplacian for a Gaussian-filtered image can be done in one step \n",
    "# of convolution. \n",
    "# ✓ Find zero-crossings\n",
    "# ✓ Find slope of zero-crossings\n",
    "\n",
    "#Custom LOG\n",
    "thres= 20\n",
    "def customLOG(image, threshold):\n",
    "\n",
    "    imageOut = gaussian(image, sigma = 0.5)\n",
    "    imageOut[np.where(imageOut < 0)] = -imageOut[np.where(imageOut < 0)]\n",
    "\n",
    "    f1 = [[-1, -1, -1], [-1, 8, -1], [-1, -1, -1]]\n",
    "    f2 = [[0, 1, 0], [1, -4, 1], [0, 1, 0]]\n",
    "\n",
    "    image_x_value = convolve2d(imageOut, f1)\n",
    "    image_x_value[np.where(image_x_value < threshold)] = 0\n",
    "    image_x_value[np.where(image_x_value >= threshold)] = 1\n",
    "\n",
    "    image_y_value = convolve2d(imageOut, f2)\n",
    "    image_y_value[np.where(image_y_value < threshold)] = 0\n",
    "    image_y_value[np.where(image_y_value >= threshold)] = 1\n",
    "\n",
    "    return imageOut, image_x_value, image_y_value\n",
    "\n",
    "imageOut, image_x_value, image_y_value = customLOG(img, thres/255)\n",
    "show_images([img, imageOut, image_x_value, image_y_value])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Morphology"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we could have also used padding  ****************  \n",
    "# but here we sliced\n",
    "\n",
    "\n",
    "# Using Min:   # only works if SE is all ones\n",
    "def erosion(image, se):\n",
    "  se_height=se.shape[0]\n",
    "  se_width= se.shape[1]\n",
    "  eroded=np.zeros(image.shape)\n",
    "  half_window=int(se_height/2)\n",
    "  height,width= image.shape\n",
    "\n",
    "  for y in range(int(se_height/2),height-int(se_height/2)):\n",
    "      for x in range(int(se_width/2),width-int(se_width/2)):\n",
    "        window=np.zeros(se.shape)\n",
    "     \n",
    "        window=image[y-half_window: y+half_window, x-half_window: x+half_window ]\n",
    "      \n",
    "        eroded[y,x]=np.min(window)    # we only used min here because our SE was all ones, if it had 0 we should use the equation in lec\n",
    "  return eroded\n",
    "\n",
    "\n",
    "se=np.ones((3,3))\n",
    "# eroded=erosion(binary_image,se)\n",
    "# sk_eroded=binary_erosion(binary_image)\n",
    "# show_images(images=[binary_image,eroded, sk_eroded], titles=[\"original binary\", \"custom_erosion\", \"Built-In Erosion\"])\n",
    "\n",
    "\n",
    "# Using Max:     # only works if SE is all ones\n",
    "def dilation(image, se):\n",
    "\n",
    "  se_height=se.shape[0]\n",
    "  se_width= se.shape[1]\n",
    "  dilated=np.zeros(image.shape)\n",
    "  half_window=int(se_height/2)\n",
    "  height,width= image.shape\n",
    "  for y in range(int(se_height/2),height-int(se_height/2)):\n",
    "      for x in range(int(se_width/2),width-int(se_width/2)):\n",
    "        window=np.zeros(se.shape)\n",
    " \n",
    "        window=image[y-half_window: y+half_window, x-half_window: x+half_window ]\n",
    "       \n",
    "        dilated[y,x]=np.max(window)\n",
    "  return dilated\n",
    "\n",
    "\n",
    "se=np.ones((3,3))\n",
    "# dilated=dilation(binary_image,se)\n",
    "# sk_dilated=binary_dilation(binary_image)\n",
    "# show_images(images=[binary_image,dilated, sk_dilated], titles=[\"original binary\", \"custom_dilation\", \"Built-In Dilation\"])\n",
    "\n",
    "\n",
    "#The following work for any SE####################################################\n",
    "\n",
    "# Another implementation using FIT:\n",
    "def Erosion(img,Array):\n",
    "    copyImage=img.copy()\n",
    "    r,c=Array.shape\n",
    "    for i in range(r//2,img.shape[0]-r//2):\n",
    "        for j in range(c//2,img.shape[1]-c//2):\n",
    "           slicedImg=img[i-r//2:i+r//2+1,j-c//2:j+c//2+1]\n",
    "           if slicedImg.all()==Array.all():\n",
    "                copyImage[i][j]= 1\n",
    "           else:\n",
    "               copyImage[i][j]= 0\n",
    "    return copyImage\n",
    "\n",
    "# Another implementation using HIT:\n",
    "def Dilation(img,Array):\n",
    "    copyImage=img.copy()\n",
    "    r,c=Array.shape\n",
    "    for i in range(r//2,img.shape[0]-r//2):\n",
    "        for j in range(c//2,img.shape[1]-c//2):\n",
    "           slicedImg=img[i-r//2:i+r//2+1,j-c//2:j+c//2+1]\n",
    "           if slicedImg.any()==Array.any():\n",
    "                copyImage[i][j]= 1\n",
    "           else:\n",
    "               copyImage[i][j]= 0\n",
    "    return copyImage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################## Contours ##################################\n",
    "\n",
    "# Note: When using \"find_contours(img, 0.8)\" the o/p is a list of contours each having:\n",
    "#                 - contour[:,0] being the Y values of the contour perimeter points\n",
    "#                 - contour[:,1] being the X values of the contour perimeter points\n",
    "\n",
    "closing=None\n",
    "contours=find_contours(closing,0.8)\n",
    "\n",
    "# Bounding boxes:\n",
    "bounding_boxes=[]\n",
    "for object in contours:\n",
    "    y_values=object[:,0]\n",
    "    x_values=object[:,1]\n",
    "    minY=np.min(y_values)\n",
    "    minx=np.min(x_values)\n",
    "    maxY=np.max(y_values)\n",
    "    maxX=np.max(x_values)\n",
    "    width=maxX-minx\n",
    "    height=maxY-minY\n",
    "    aspect_ratio=width/height\n",
    "    if aspect_ratio >= 2.5 and aspect_ratio <= 3.5 and width <70 and width >60:\n",
    "        bounding_boxes.append([minx, maxX, minY, maxY])\n",
    "print(len(bounding_boxes))\n",
    "\n",
    "img_gray=rgb2gray(img)\n",
    "\n",
    "for box in bounding_boxes:\n",
    "    [Xmin, Xmax, Ymin, Ymax] = box\n",
    "    rr, cc = rectangle(start = (Ymin,Xmin), end = (Ymax,Xmax), shape=img_gray.shape)\n",
    "    img[rr, cc] = 1 #set color white"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#################### Skeletonize #####################\n",
    "skeleton=skeletonize(binary_image)\n",
    "thinned5=thin(binary_image,  max_num_iter=5)\n",
    "thinned10=thin(binary_image,  max_num_iter=10)\n",
    "thinned15=thin(binary_image,  max_num_iter=15)\n",
    "thinned20=thin(binary_image,  max_num_iter=20)\n",
    "\n",
    "# when we increase iterations, it gets more thinned"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Textures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_glcm_features(gray_scale_img):\n",
    "    \"\"\"\n",
    "    Given a grayscale image with graylevels from 0 - 255, this function returns the contrast\n",
    "    and the homogeneity features of the image with the help of GLCM\n",
    "    \"\"\"\n",
    "    # Tip: Make sure you understand the input-output of everything you write, \n",
    "    # not doing that results in bugs that make you believe the lab is long\n",
    "    graycomat=graycomatrix(image=gray_scale_img, distances=[1] , angles=[0])\n",
    " \n",
    "\n",
    "    contrast=graycoprops(graycomat,'contrast')\n",
    "    homogeneity=graycoprops(graycomat, 'homogeneity')\n",
    "    \n",
    "    return contrast, homogeneity\n",
    "\n",
    "# You don't need to understand how this function works\n",
    "def get_fname_images_tuple(directory):\n",
    "    fnames = os.listdir(directory)\n",
    "    to_return = []\n",
    "    for fn in fnames:\n",
    "        if fn[-3:] == 'jpg':\n",
    "            path = os.path.join(directory, fn)\n",
    "            gray_scale_image = (rgb2gray(io.imread(path)) * 255).astype(np.uint8)\n",
    "            to_return.append((fn, gray_scale_image))\n",
    "        else:\n",
    "            print('This file has been skipped', fn)\n",
    "    return to_return\n",
    "\n",
    "# You don't need to understand how this function works\n",
    "def plot_2d_features_with_names(names_fts_list, xlabel, ylabel):\n",
    "    x = [names_fts[1][0] for names_fts in names_fts_list]\n",
    "    y = [names_fts[1][1] for names_fts in names_fts_list]\n",
    "    txts = [names_fts[0] for names_fts in names_fts_list]\n",
    "    \n",
    "    fig, ax = plt.subplots()\n",
    "    ax.scatter(x, y)\n",
    "\n",
    "    for i, txt in enumerate(txts):\n",
    "        ax.annotate(txt, (x[i], y[i]))\n",
    "    ax.grid()\n",
    "    ax.set_xlabel(xlabel)\n",
    "    ax.set_ylabel(ylabel)\n",
    "    fig = plt.gcf()\n",
    "    fig.set_size_inches(13, 8)\n",
    "    \n",
    "    \n",
    "fn_img_list = get_fname_images_tuple(r'imgs_patches')\n",
    "\n",
    "fn_ft_list = []\n",
    "for fn, img in fn_img_list:\n",
    "    fn_ft_list.append((fn, get_glcm_features(img)))\n",
    "    \n",
    "plot_2d_features_with_names(fn_ft_list, 'contrast', 'homogeneity')\n",
    "\n",
    "\n",
    "# we should convert to uint8\n",
    "contrast,homogenity=get_glcm_features(np.uint8(rgb2gray(io.imread('imgs_patches/cotton1.jpg'))*255))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################ LBP  ########################################\n",
    "\n",
    "#- For each pixel p, create an 8-bit number b1 b2 b3 b4 b5 b6 b7 b8, where bi = 0 if neighbor i has value less than or equal to p’s value and 1 otherwise\n",
    "\n",
    "def get_lbp_hist(grayscale_img):\n",
    "    img=np.pad(grayscale_img,pad_width=1)\n",
    "    my_hist=np.zeros(256)\n",
    "    lbp=np.zeros((img.shape))\n",
    "    for i in range(1,img.shape[0]):\n",
    "        for j in range(1,img.shape[1]):\n",
    "            oneD=[]\n",
    "            window=img[i-1:i+2,j-1:j+2]\n",
    "            pixel=img[i,j]\n",
    "            for _i in range(window.shape[0]):\n",
    "                for _j in range(window.shape[1]):\n",
    "                    if not(_i == 1 and _j == 1):\n",
    "                        if pixel < window[_i,_j]: \n",
    "                            oneD.append(1)\n",
    "                        else:\n",
    "                            oneD.append(0)\n",
    "            _bintodec=bintodec(oneD)\n",
    "        \n",
    "            lbp[i,j]=_bintodec\n",
    "            my_hist[_bintodec]+=1\n",
    "\n",
    "    return my_hist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Segmentation p1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nth important"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HOG"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Step 1: Compute Gradient: Magnitude & Direction [Per Pixel]\n",
    "- Step 2: Extract a square window (called “block”) of some size. (same size)\n",
    "- Step 3: Divide block into a square grid of sub-blocks (called “cells”) (2x2 grid in our example, resulting in four cells).\n",
    "- Step 4: Compute orientation histogram of each cell. \n",
    "You calculate the gradient in each pixel and then make a histogram for each cell.\n",
    "We have a pixel, its magnitude and direction. We then want to put this into a histogram \n",
    "where pins of histogram are directions and value is the magnitude\n",
    "- Step 5: Concatenate the four histograms.: So for each block we will have 4 histograms (since the block had 4 cells)\n",
    "<br>\n",
    "\n",
    "Let vector v be concatenation of the four histograms from step 4. \n",
    "<br>\n",
    "\n",
    "- Step 6: normalize v. An option for how to do it: Divide v by its Euclidean norm. Each block will have a normalized histogram. (1 vector for each block)\n",
    "\n",
    "- Final feature vector: Concatenate histograms : Make it a 1D vector of length 3780  ==> # of Blocks * # of cells * # of bins = 105x4x9 = 3,780\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check its lab\n",
    "# it has the following:\n",
    "#   -compute_gradient function\n",
    "# \t-compute_gradient_magnitude function\n",
    "# \t-compute_gradient_direction function\n",
    "# \t-find_nearest_bins to form the vector in slide 15\n",
    "# \t-update_histogram_bins to fill the vector with the magnitudes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check its lab\n",
    "# it has the following:\n",
    "#\t-cv2.resize\n",
    "#   -hsv histogtram\n",
    "#   -cv2.HOG implemented"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Segmentation p2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def automatic_thresholding(image):\n",
    "    img=np.copy(image)\n",
    "    img = img.astype(\"uint8\")\n",
    "    \n",
    "    img_hist = histogram(img, nbins=256)\n",
    "    # print(img_hist[0].shape)\n",
    "    # print(img_hist[0])      # counts\n",
    "    # print('-----------------------------')\n",
    "    # print(img_hist[1].shape) # gray levels\n",
    "    # print(img_hist[1])\n",
    "    # showHist(img)\n",
    "\n",
    "    counts_img_hist=img_hist[0]\n",
    "    graylvls_img=img_hist[1]\n",
    "    total_px_sum=np.sum(counts_img_hist)\n",
    "    Ti=np.round(np.dot(counts_img_hist,graylvls_img)/total_px_sum)\n",
    "    #print(Ti) #93.0\n",
    "\n",
    "\n",
    "    Told=Ti\n",
    "    Tnew=0\n",
    "    while(Tnew!=Told):\n",
    "        low_gray_lvls=graylvls_img[graylvls_img<Told]\n",
    "        high_gray_lvls=graylvls_img[graylvls_img>=Told]\n",
    "\n",
    "        low_gray_lvls_counts=counts_img_hist[graylvls_img<Told]\n",
    "        high_gray_lvls_counts=counts_img_hist[graylvls_img>=Told]\n",
    "        total_px_sum_low=np.sum(low_gray_lvls_counts)\n",
    "        total_px_sum_high=np.sum(high_gray_lvls_counts)\n",
    "\n",
    "        Tlow = np.round(np.sum(low_gray_lvls * low_gray_lvls_counts) / total_px_sum_low) if total_px_sum_low != 0 else 0\n",
    "        Thigh = np.round(np.sum(high_gray_lvls * high_gray_lvls_counts) / total_px_sum_high) if total_px_sum_high != 0 else 0\n",
    "\n",
    "        Tnew= np.round((Tlow+Thigh)/2)\n",
    "        #print(Tnew)\n",
    "        if Tnew == Told:\n",
    "            break\n",
    "        else:\n",
    "            Told=Tnew\n",
    "            Tnew=0 # saturated at 114.0\n",
    "\n",
    "    Tfinal=Told\n",
    "\n",
    "    img[img<Tfinal]=0\n",
    "    img[img>=Tfinal]=1\n",
    "\n",
    "    return img\n",
    "\n",
    "\n",
    "def partitionby4(image):\n",
    "    height,width= image.shape\n",
    "    center_x = width // 2\n",
    "    center_y = height // 2\n",
    "    top_left = image[:center_y, :center_x]\n",
    "    top_right = image[:center_y, center_x:]\n",
    "    bottom_left = image[center_y:, :center_x]\n",
    "    bottom_right = image[center_y:, center_x:]\n",
    "    return top_left, top_right, bottom_left, bottom_right\n",
    "\n",
    "\n",
    "\n",
    "def threshold_and_merge(image):   \n",
    "    top_left, top_right, bottom_left, bottom_right=partitionby4(image)\n",
    "    tl_th=automatic_thresholding(top_left)\n",
    "    tr_th=automatic_thresholding(top_right)\n",
    "    bl_th=automatic_thresholding(bottom_left)\n",
    "    br_th=automatic_thresholding(bottom_right)\n",
    "    merged_image= np.zeros((image.shape))\n",
    "    merged_image = np.vstack((np.hstack((tl_th, tr_th)),\n",
    "                              np.hstack((bl_th, br_th))))\n",
    "    return merged_image\n",
    "\n",
    "\n",
    "def local_thrs(image,n):\n",
    "    height, width = image.shape\n",
    "    partitions = [image[i*height//n:(i+1)*height//n, j*width//n:(j+1)*width//n] for i in range(n) for j in range(n)] \n",
    "    thresholded_partitions = [automatic_thresholding(partition) for partition in partitions]\n",
    "    merged_image = np.vstack([np.hstack(thresholded_partitions[i*n:(i+1)*n]) for i in range(n)])\n",
    "    return merged_image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the next are just important algos in lecs about those topics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Segmentation p3 algos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SIFT algos"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
